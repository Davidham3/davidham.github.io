<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=6.0.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=6.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png?v=6.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=6.0.0">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=6.0.0" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Davidham的博客，写点学习笔记啥的，邮箱17120410@bjtu.edu.cn">
<meta property="og:type" content="website">
<meta property="og:title" content="categories">
<meta property="og:url" content="http://yoursite.com/categories/index.html">
<meta property="og:site_name" content="Davidham&#39;s blog">
<meta property="og:description" content="Davidham的博客，写点学习笔记啥的，邮箱17120410@bjtu.edu.cn">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-02-19T13:29:39.253Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="categories">
<meta name="twitter:description" content="Davidham的博客，写点学习笔记啥的，邮箱17120410@bjtu.edu.cn">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Gemini',
    version: '6.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/categories/"/>





  <title>Deep Residual Learning for Image Recognition | Davidham's blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?c30fad310ff0f715b4bafabc30583f7d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Davidham's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">修电脑的</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/blog/2018/03/04/deep-residual-learning-for-image-recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Davidham">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/blog/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Davidham's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Deep Residual Learning for Image Recognition</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-04T18:59:20+08:00">2018-03-04</time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/论文阅读笔记/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>CVPR 2015，ResNet，原文链接：<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a><br><a id="more"></a></p>
<h1 id="Deep-Residual-Learning-for-Image-Recongnition"><a href="#Deep-Residual-Learning-for-Image-Recongnition" class="headerlink" title="Deep Residual Learning for Image Recongnition"></a>Deep Residual Learning for Image Recongnition</h1><h2 id="problems"><a href="#problems" class="headerlink" title="problems"></a>problems</h2><p>When deeper networks are able to start converging, a degradation problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in [11, 42] and thoroughly verified by our experiments. Fig. 1 shows a typical example.<br><img src="/blog/2018/03/04/deep-residual-learning-for-image-recognition/Fig1.PNG" alt="Fig1"></p>
<center>Figure 1. Training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer “plain” networks. The deeper network has higher training error, and thus test error. Similar phenomena on ImageNet is presented in Fig. 4.</center>

<p>The degradation (of training accuracy) indicates that not all systems are similarly easy to optimize. Let us consider a shallower architecture and its deeper counterpart that adds more layers onto it. There exists a solution <em>by construction</em> to the deeper model: the added layers are <em>identity</em> mapping and the other layers are copied from the learned shallower model. The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart. But experiments show that our current solvers on hand are unable to find solutions that are comparably good or better than the constructed solution (or unable to do so in feasible time).</p>
<h2 id="Deep-Residual-Learning"><a href="#Deep-Residual-Learning" class="headerlink" title="Deep Residual Learning"></a>Deep Residual Learning</h2><h3 id="Residual-Learning"><a href="#Residual-Learning" class="headerlink" title="Residual Learning"></a>Residual Learning</h3><p>Let us consider $\mathcal{H}(x)$ as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with $x$ denoting the inputs to the first of these layers. If one hypothesizes that multiple nonlinear layers can asymptotically approximate complicated functions, then it is equivalent to hypothesize that they can asymptotically approximate the residual functions, $i.e.$, $\mathcal{H}(x)-x$ (assuming that the input and output are of the same dimensions). So rather than expect stacked layers to approximate $\mathcal{H}(x)$, we explicitly let these layers approximate a residual function $\mathcal{F}(x):=\mathcal{H}(x)-x$. The original function thus becomes $\mathcal{F}(x)+x$. Although both forms should be able to asymptotically approximate the desired functions (as hypothesized), the ease of learning might be different.</p>
<h3 id="Identity-Mapping-by-Shortcuts"><a href="#Identity-Mapping-by-Shortcuts" class="headerlink" title="Identity Mapping by Shortcuts"></a>Identity Mapping by Shortcuts</h3><script type="math/tex; mode=display">y = \mathcal{F}(x, {W_i})+x</script><p>Here $x$ and $y$ are the input and output vectors of the layers considered. The function $\mathcal{F}(x, W_i)$ represents the residual mapping to be learned. For the example in Fig. 2 that has two layers, $\mathcal{F} = W_2\sigma (W_1x)$ in which $\sigma $ denotes ReLU and the bias are omitting for simplifying notations. The operation $\mathcal{F}+x$ is performed by a shortcut connection and element-wise addition. We adopt the second nonlinearity after the addtion (<em>i.e.</em>, $\sigma(y)$, see Fig.2).<br><img src="/blog/2018/03/04/deep-residual-learning-for-image-recognition/Fig2.PNG" alt="Fig2"></p>
<center>Figure2. Residual learning: a building block.</center>

<p>The dimensions of $x$ and $\mathcal{F}$ must be equal in Eqn.(1). If this is not the case (<em>e.g.</em>, when changing the input/output channels), we can perform a linear projection $W_s$ by the shortcut connections to match the dimensions:</p>
<script type="math/tex; mode=display">y = \mathcal{F}(x, {W_i}) + W_sx</script><p>We can also use a square matrix $W_s$ in Eqn.(1). But we will show by experiments that the identity mapping is sufficient for addressing the degradation problem and is economical, and thus $W_s$ is only used when matching dimensions.<br>We also note that although the above notations are about fully-connected layers for simplicity, they are applicable to convolutional layers. The function $\mathcal{F}(x, {W_i})$ can represent multiple convolutional layers. The element-wise addition is performed on two feature maps, channel by channel.</p>
<h2 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h2><p>The identity shortcuts can be directly used when the input and output are of the same dimensions (solid line shortcuts in Fig.3). When the dimensions increase (dotted line shortcuts in Fig.3), we consider two options: (A) The shortcut still performs identity mapping, with extra zero entries padded for increasing dimensions. This option introduces no extra parameter; (B) The projection shortcut in Eqn.(2) is used to match dimensions (done by $1 \times 1$ convolutions). For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2.<br><img src="/blog/2018/03/04/deep-residual-learning-for-image-recognition/Fig3.PNG" alt="Fig3"></p>
<center>Figure3. Example network architectures for ImageNet. <b>Left</b>: the VGG-19 model. <b>Middle</b>: a plain network with 34-parameter layers. **Right**: a residual network with 34 parameter layers. The dotted shortcuts increase dimensions. <b>Table 1</b> shows more details and other variants.</center>

<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>Our implementation for ImageNet follows the practice in <em>[Imagenet classification<br>with deep convolutional neural networks]</em> and <em>[Very deep convolutional networks for large-scale image recognition]</em>. </p>
<ol>
<li>The Image is resized with its shorter side randomly sampled in $[256, 480]$ for scale agumentation.</li>
<li>A $224 \times 224$ crop is randomly sampled from an image or its horizontal flip, with the per-pixel mean subtracted.</li>
<li>The standard color augmentation in <em>Imagenet classification<br>with deep convolutional neural networks</em> is used.</li>
<li>We adopt batch normalization (BN) right after each convolution and before activation.</li>
<li>We initialize the weights as in <em>Delving deep into rectifiers:<br>Surpassing human-level performance on imagenet classification</em> and train all plain/residual nets from scratch.</li>
<li>We use SGD with a mini-batch size of 256.</li>
<li>The learning rate starts from 0.1 and is divided by 10 when the error plateaus, and the models are trained from up to $60 \times 10^4$ iterations.</li>
<li>We use a weight decay of 0.0001 and a momentum of 0.9.</li>
<li>We do not use dropout, following the practice in <em>Batch normalization: Accelerating deep<br>network training by reducing internal covariate shift</em>.</li>
<li>In testing, for comparison studies we adopt the standard 10-crop testing.[<em>Imagenet classification<br>with deep convolutional neural networks</em>]</li>
<li>For best results, we adopt the fully-convolutional form as in <em>Very deep convolutional networks for large-scale image recognition</em> and <em>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</em>, and average the scores at multiple scales (images are resized such that the shorter side is in $\{224, 256, 384, 480, 640\}$.</li>
</ol>
<h2 id="ImageNet-classification"><a href="#ImageNet-classification" class="headerlink" title="ImageNet classification"></a>ImageNet classification</h2><h3 id="Deeper-Bottleneck-Architecture"><a href="#Deeper-Bottleneck-Architecture" class="headerlink" title="Deeper Bottleneck Architecture"></a>Deeper Bottleneck Architecture</h3><p>Next we describe our deeper nets for ImageNet. Because of concerns on the training time that we can afford, we modify the building block as a <em>bottleneck</em> design. For each residual function $\mathcal{F}$, we use a stack of 3 layers instead of 2 (Fig. 5). The three layers are $1 \times 1$, $3 \times 3$, and $1 \times 1$ convolutions, where the $1 \times 1$ layers are responsible for reducing and then increasing (restoring) dimensions, leaving the $3 \times 3$ layer a bottleneck with smaller input/output dimensions. Fig. 5 shows an example, where both designs have similar time complexity.<br>The parameter-free indentity shortcuts are particularly important for the bottleneck architectures. If the identity</p>
<h2 id="CIFAR-10-and-Analysis"><a href="#CIFAR-10-and-Analysis" class="headerlink" title="CIFAR-10 and Analysis"></a>CIFAR-10 and Analysis</h2><p>The plain/residual architectures follow the form in Fig.3(middle/right). The network inputs are $32 \times 32$ images, with the per-pixel mean subtracted. The first layer is $3 \times 3$ convolutions. Then we use a stack of $6n$ layers with $3 \times 3$ convolutions on the feature maps of sizes $\{32, 16, 8\}$ respectively, with $2n$ layers for each feature map size. The numbers of filters are $\{16, 32, 64\}$ respectively, with $2n$ layers for each feature map size. The subsampling is performed by convolutions with a stride of 2. The network ends with a global average pooling, a 10-way fully-connected layer, and softmax.<br>When shortcut connections are used, they are connected to the pairs of $3 \times 3$ layers(totally $3n$ shortcuts). On this dataset we use identity shortcuts in all cases (<em>i.e.</em>, option A), so our residual models have exactly the same depth, width and number of parameters as the plain counterparts.<br>We use a weight decay of 0.0001 and momentum of 0.9, and adopt the weight initialization in <em>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</em> and BN in <em>Accelerating deep network training by reducing internal covariate shift</em> but with no dropout. These models are trained with a mini-batch size of 128 on two GPUs. We start with a learning rate of 0.1, divide it by 10 at 32k and 48k iterations, and terminate training at 64k iterations, which is determined on a 45k/5k train/val split. We follow the simple data augmentation in <em>Deeply-supervised nets</em> for training: 4 pixels are padded on each side, and a $32 \times 32$ crop is randomly sampled from the padded image or its horizontal flip. For testing, we only evaluate the single view of the original $32 \times 32$ image.<br>We compare $n=\{3, 5, 7, 9\}$, leading to 20, 32, 44, and 56-layer networks.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/deep-learning/" rel="tag"># deep learning</a>
          
            <a href="/blog/tags/machine-learning/" rel="tag"># machine learning</a>
          
            <a href="/blog/tags/resnet/" rel="tag"># ResNet</a>
          
            <a href="/blog/tags/cvpr/" rel="tag"># CVPR</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/03/02/image-super-resolution-using-deep-convolutional-networks/" rel="next" title="Image Super-Resolution Using Deep Convolutional Networks">
                <i class="fa fa-chevron-left"></i> Image Super-Resolution Using Deep Convolutional Networks
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/03/08/identity-mappings-in-deep-residual-networks/" rel="prev" title="Identity Mappings in Deep Residual Networks">
                Identity Mappings in Deep Residual Networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNzEwMS8xMzYzNw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/blog/uploads/avatar.jpg"
                alt="Davidham" />
            
              <p class="site-author-name" itemprop="name">Davidham</p>
              <p class="site-description motion-element" itemprop="description">Davidham的博客，写点学习笔记啥的，邮箱17120410@bjtu.edu.cn</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Davidham3" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://weibo.com/Davidham3" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-globe"></i>微博</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Residual-Learning-for-Image-Recongnition"><span class="nav-number">1.</span> <span class="nav-text">Deep Residual Learning for Image Recongnition</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#problems"><span class="nav-number">1.1.</span> <span class="nav-text">problems</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Residual-Learning"><span class="nav-number">1.2.</span> <span class="nav-text">Deep Residual Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Residual-Learning"><span class="nav-number">1.2.1.</span> <span class="nav-text">Residual Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Identity-Mapping-by-Shortcuts"><span class="nav-number">1.2.2.</span> <span class="nav-text">Identity Mapping by Shortcuts</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Residual-Network"><span class="nav-number">1.3.</span> <span class="nav-text">Residual Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation"><span class="nav-number">1.4.</span> <span class="nav-text">Implementation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ImageNet-classification"><span class="nav-number">1.5.</span> <span class="nav-text">ImageNet classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Deeper-Bottleneck-Architecture"><span class="nav-number">1.5.1.</span> <span class="nav-text">Deeper Bottleneck Architecture</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CIFAR-10-and-Analysis"><span class="nav-number">1.6.</span> <span class="nav-text">CIFAR-10 and Analysis</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Davidham</span>

  

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Gemini</a> v6.0.0</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>





  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=65896580";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
























  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=6.0.0"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=6.0.0"></script>



  
  


  <script type="text/javascript" src="/blog/js/src/affix.js?v=6.0.0"></script>

  <script type="text/javascript" src="/blog/js/src/schemes/pisces.js?v=6.0.0"></script>



  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=6.0.0"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=6.0.0"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=6.0.0"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
